"""
æ™ºè°±AI GLM-4-AIR ä¸“ç”¨å®¢æˆ·ç«¯
æ”¯æŒGLM-4-AIRæ¨¡å‹å’Œembedding-3å‘é‡æ¨¡å‹
"""

import os
import asyncio
import httpx
import json
import numpy as np
from typing import Dict, Any, List, Optional

class ZhipuGLM4AirClient:
    def __init__(self):
        self.api_key = os.getenv("ZHIPU_API_KEY")
        self.base_url = "https://open.bigmodel.cn/api/paas/v4"
        
    async def call_glm4_air(self, question: str, temperature: float = 0.7) -> Dict[str, Any]:
        """è°ƒç”¨GLM-4-AIRæ¨¡å‹"""
        if not self.api_key:
            return {"error": "ZhipuAI API key not configured", "success": False}
            
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # å°è¯•ä¸åŒçš„æ¨¡å‹åç§°
        model_names = ["glm-4-air", "glm-4-airx", "GLM-4-Air"]
        
        for model_name in model_names:
            data = {
                "model": model_name,
                "messages": [
                    {"role": "user", "content": question}
                ],
                "max_tokens": 500,
                "temperature": temperature
            }
            
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.post(
                        f"{self.base_url}/chat/completions",
                        headers=headers,
                        json=data,
                        timeout=30.0
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        return {
                            "model": f"GLM-4-Air ({model_name})",
                            "response": result["choices"][0]["message"]["content"],
                            "confidence": 0.85,
                            "success": True,
                            "model_used": model_name
                        }
                    elif response.status_code == 400:
                        # æ¨¡å‹åç§°é”™è¯¯ï¼Œå°è¯•ä¸‹ä¸€ä¸ª
                        print(f"æ¨¡å‹ {model_name} ä¸å¯ç”¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
                        continue
                    else:
                        error_text = response.text
                        print(f"æ¨¡å‹ {model_name} é”™è¯¯: {response.status_code} - {error_text}")
                        
                        # å¦‚æœæ˜¯æ¬ è´¹ä½†é’ˆå¯¹ç‰¹å®šæ¨¡å‹ï¼Œç»§ç»­å°è¯•å…¶ä»–æ¨¡å‹åç§°
                        if "1113" in error_text and len(model_names) > 1:
                            continue
                        
                        return {
                            "model": f"GLM-4-Air ({model_name})",
                            "error": f"API error: {response.status_code} - {error_text}",
                            "success": False
                        }
            except Exception as e:
                print(f"æ¨¡å‹ {model_name} å¼‚å¸¸: {str(e)}")
                continue
        
        return {
            "model": "GLM-4-Air",
            "error": "æ‰€æœ‰æ¨¡å‹åç§°éƒ½å°è¯•å¤±è´¥",
            "success": False
        }
    
    async def get_embedding(self, text: str) -> Dict[str, Any]:
        """è·å–æ–‡æœ¬å‘é‡ (embedding-3)"""
        if not self.api_key:
            return {"error": "ZhipuAI API key not configured", "success": False}
            
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "embedding-3",
            "input": text
        }
        
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/embeddings",
                    headers=headers,
                    json=data,
                    timeout=30.0
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return {
                        "embedding": result["data"][0]["embedding"],
                        "success": True,
                        "dimensions": len(result["data"][0]["embedding"])
                    }
                else:
                    return {
                        "error": f"Embedding API error: {response.status_code} - {response.text}",
                        "success": False
                    }
        except Exception as e:
            return {
                "error": str(e),
                "success": False
            }
    
    def calculate_similarity(self, embedding1: List[float], embedding2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
        try:
            vec1 = np.array(embedding1)
            vec2 = np.array(embedding2)
            
            # ä½™å¼¦ç›¸ä¼¼åº¦
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            similarity = dot_product / (norm1 * norm2)
            return float(similarity)
        except Exception as e:
            print(f"è®¡ç®—ç›¸ä¼¼åº¦é”™è¯¯: {e}")
            return 0.0

async def test_zhipu_models():
    """æµ‹è¯•æ™ºè°±AIæ¨¡å‹"""
    client = ZhipuGLM4AirClient()
    
    print("ğŸ§ª æµ‹è¯•æ™ºè°±AI GLM-4-AIRæ¨¡å‹...")
    print("=" * 50)
    
    # æµ‹è¯•é—®é¢˜
    questions = [
        "2+2ç­‰äºå¤šå°‘ï¼Ÿ",
        "What is 2+2?",
        "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹è¯­è¨€",
        "Hello, how are you?"
    ]
    
    for question in questions:
        print(f"\nâ“ é—®é¢˜: {question}")
        print("-" * 30)
        
        # æµ‹è¯•GLM-4-AIR
        result = await client.call_glm4_air(question)
        if result.get("success"):
            print(f"âœ… {result['model']}: {result['response']}")
            print(f"   ä¿¡å¿ƒåº¦: {result['confidence']}")
        else:
            print(f"âŒ é”™è¯¯: {result.get('error', 'Unknown error')}")
        
        # æµ‹è¯•embedding
        print(f"\nğŸ” æµ‹è¯•å‘é‡åŒ–...")
        embedding_result = await client.get_embedding(question)
        if embedding_result.get("success"):
            embedding = embedding_result["embedding"]
            print(f"âœ… å‘é‡ç»´åº¦: {embedding_result['dimensions']}")
            print(f"   å‘é‡å‰5ä¸ªå€¼: {embedding[:5]}")
            
            # æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—
            if len(questions) > 1:
                other_question = questions[0] if question != questions[0] else questions[1]
                other_embedding_result = await client.get_embedding(other_question)
                if other_embedding_result.get("success"):
                    similarity = client.calculate_similarity(
                        embedding, 
                        other_embedding_result["embedding"]
                    )
                    print(f"   ä¸ '{other_question}' çš„ç›¸ä¼¼åº¦: {similarity:.3f}")
        else:
            print(f"âŒ å‘é‡åŒ–é”™è¯¯: {embedding_result.get('error', 'Unknown error')}")

if __name__ == "__main__":
    asyncio.run(test_zhipu_models()) 